{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# üîç Advanced Search with Filters\n",
    "\n",
    "Welcome to the Airweave advanced search tutorial! This notebook demonstrates how to use Airweave's powerful search capabilities with metadata filtering to find exactly what you need across all your connected data sources.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "- How to perform basic searches across all your data\n",
    "- Using filters to narrow results by source, date, and metadata\n",
    "- Understanding response types (raw vs completion)\n",
    "- Implementing pagination for large result sets\n",
    "- Leveraging query expansion for better recall\n",
    "- Common pitfalls and how to avoid them\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before starting, ensure you have:\n",
    "1. An Airweave API key (get one at [app.airweave.ai](https://app.airweave.ai))\n",
    "2. At least one collection with connected data sources\n",
    "3. Python 3.8+ with the required packages installed\n",
    "\n",
    "## Documentation Links\n",
    "\n",
    "- [Search Concepts](https://docs.airweave.ai/search/concepts)\n",
    "- [Using Filters](https://docs.airweave.ai/search/filters)\n",
    "- [API Reference](https://docs.airweave.ai/api-reference/collections/search-collection-advanced)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Setup and Configuration\n",
    "\n",
    "First, let's install the required packages and set up our environment:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install airweave-sdk pandas matplotlib seaborn python-dotenv\n",
    "\n",
    "# Import necessary libraries\n",
    "import json\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from typing import List, Dict\n",
    "\n",
    "# Data manipulation and visualization\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Airweave imports\n",
    "from airweave import AirweaveSDK\n",
    "from airweave.schemas.search import SearchRequest\n",
    "from qdrant_client.http.models import (\n",
    "    Filter, \n",
    "    FieldCondition, \n",
    "    MatchValue, \n",
    "    MatchAny,\n",
    "    DatetimeRange,\n",
    "    Range\n",
    ")\n",
    "\n",
    "# Configure display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure API credentials\n",
    "# Option 1: Set directly (not recommended for production)\n",
    "API_KEY = \"your-api-key-here\"\n",
    "COLLECTION_ID = \"your-collection-id-here\"\n",
    "\n",
    "# Option 2: Load from environment variables (recommended)\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "# API_KEY = os.getenv(\"AIRWEAVE_API_KEY\")\n",
    "# COLLECTION_ID = os.getenv(\"AIRWEAVE_COLLECTION_ID\")\n",
    "\n",
    "# Initialize the SDK\n",
    "client = AirweaveSDK(api_key=API_KEY)\n",
    "\n",
    "# Helper function to display results nicely\n",
    "def display_results(results: List[Dict], title: str = \"Search Results\"):\n",
    "    \"\"\"Display search results in a formatted table.\"\"\"\n",
    "    if not results:\n",
    "        display(Markdown(f\"### {title}\\n\\n*No results found*\"))\n",
    "        return\n",
    "    \n",
    "    # Extract key fields for display\n",
    "    data = []\n",
    "    for r in results:\n",
    "        payload = r.get('payload', {})\n",
    "        data.append({\n",
    "            'Score': f\"{r.get('score', 0):.3f}\",\n",
    "            'Source': payload.get('source_name', 'Unknown'),\n",
    "            'Title': payload.get('title', payload.get('name', 'Untitled'))[:80] + '...',\n",
    "            'Created': payload.get('created_at', 'Unknown')[:10] if payload.get('created_at') else 'Unknown',\n",
    "            'Type': payload.get('entity_type', 'Unknown')\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    display(Markdown(f\"### {title} ({len(results)} results)\"))\n",
    "    display(df)\n",
    "\n",
    "print(\"‚úÖ SDK initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Basic Search\n",
    "\n",
    "Let's start with the fundamentals - performing a simple search across all your connected data sources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Simple text search\n",
    "response = await client.collections.search_collection(\n",
    "    readable_id=COLLECTION_ID,\n",
    "    query=\"customer onboarding process\",\n",
    "    limit=5\n",
    ")\n",
    "\n",
    "# Display results\n",
    "display_results(response.results, \"Basic Search Results\")\n",
    "\n",
    "# Show the structure of a single result\n",
    "if response.results:\n",
    "    display(Markdown(\"### Structure of a Search Result\"))\n",
    "    print(json.dumps(response.results[0], indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Response Types\n",
    "\n",
    "Airweave provides two response types:\n",
    "- **Raw**: Returns the actual search results as structured data\n",
    "- **Completion**: Returns an AI-generated summary of the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Search with AI completion\n",
    "completion_response = await client.collections.search_collection(\n",
    "    readable_id=COLLECTION_ID,\n",
    "    query=\"What are our current security policies and procedures?\",\n",
    "    response_type=\"completion\",\n",
    "    limit=10\n",
    ")\n",
    "\n",
    "display(Markdown(\"### AI-Generated Summary\"))\n",
    "display(Markdown(completion_response.completion))\n",
    "\n",
    "# Also show the number of sources used\n",
    "display(Markdown(f\"\\n*Based on {len(completion_response.results)} search results*\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Filtering Deep Dive\n",
    "\n",
    "Now let's explore how filters can help you find exactly what you need. Filters allow you to narrow results based on metadata like source, date, priority, and more.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Filter by source (CASE-SENSITIVE!)\n",
    "display(Markdown(\"### üö® Important: source_name is case-sensitive!\"))\n",
    "\n",
    "# This will work if you have GitHub data\n",
    "github_request = SearchRequest(\n",
    "    query=\"bug fixes and improvements\",\n",
    "    filter=Filter(\n",
    "        must=[\n",
    "            FieldCondition(\n",
    "                key=\"source_name\",\n",
    "                match=MatchValue(value=\"GitHub\")  # Must match exactly!\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    limit=5\n",
    ")\n",
    "\n",
    "github_response = await client.collections.search_collection_advanced(\n",
    "    readable_id=COLLECTION_ID,\n",
    "    search_request=github_request\n",
    ")\n",
    "\n",
    "display_results(github_response.results, \"GitHub-only Results\")\n",
    "\n",
    "# Common mistake: wrong case\n",
    "wrong_case_request = SearchRequest(\n",
    "    query=\"bug fixes and improvements\",\n",
    "    filter=Filter(\n",
    "        must=[\n",
    "            FieldCondition(\n",
    "                key=\"source_name\",\n",
    "                match=MatchValue(value=\"github\")  # lowercase won't match \"GitHub\"!\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    limit=5\n",
    ")\n",
    "\n",
    "wrong_response = await client.collections.search_collection_advanced(\n",
    "    readable_id=COLLECTION_ID,\n",
    "    search_request=wrong_case_request\n",
    ")\n",
    "\n",
    "display(Markdown(\"### ‚ùå Wrong case example (github vs GitHub):\"))\n",
    "display_results(wrong_response.results, \"Results with wrong case\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: Handle case variations with MatchAny\n",
    "case_insensitive_request = SearchRequest(\n",
    "    query=\"bug fixes and improvements\",\n",
    "    filter=Filter(\n",
    "        must=[\n",
    "            FieldCondition(\n",
    "                key=\"source_name\",\n",
    "                match=MatchAny(any=[\"GitHub\", \"github\", \"GITHUB\"])  # Cover common variations\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    limit=5\n",
    ")\n",
    "\n",
    "case_insensitive_response = await client.collections.search_collection_advanced(\n",
    "    readable_id=COLLECTION_ID,\n",
    "    search_request=case_insensitive_request\n",
    ")\n",
    "\n",
    "display(Markdown(\"### ‚úÖ Case-insensitive approach using MatchAny:\"))\n",
    "display_results(case_insensitive_response.results, \"Case-insensitive Results\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: Date range filtering\n",
    "display(Markdown(\"### Date Range Filtering\"))\n",
    "\n",
    "# Find items from the last 30 days\n",
    "thirty_days_ago = datetime.now(timezone.utc) - timedelta(days=30)\n",
    "\n",
    "recent_items_request = SearchRequest(\n",
    "    query=\"updates and changes\",\n",
    "    filter=Filter(\n",
    "        must=[\n",
    "            FieldCondition(\n",
    "                key=\"created_at\",\n",
    "                range=DatetimeRange(gte=thirty_days_ago)\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    limit=10\n",
    ")\n",
    "\n",
    "recent_response = await client.collections.search_collection_advanced(\n",
    "    readable_id=COLLECTION_ID,\n",
    "    search_request=recent_items_request\n",
    ")\n",
    "\n",
    "display_results(recent_response.results, \"Items from Last 30 Days\")\n",
    "\n",
    "# Visualize the date distribution\n",
    "if recent_response.results:\n",
    "    dates = [r['payload'].get('created_at', '')[:10] for r in recent_response.results if r['payload'].get('created_at')]\n",
    "    if dates:\n",
    "        df_dates = pd.DataFrame({'date': pd.to_datetime(dates)})\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        df_dates['date'].hist(bins=20)\n",
    "        plt.title('Distribution of Results by Date')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Count')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 5: Complex multi-condition filtering\n",
    "display(Markdown(\"### Complex Multi-Condition Search\"))\n",
    "\n",
    "# Find high-priority items from multiple sources, excluding resolved ones\n",
    "complex_request = SearchRequest(\n",
    "    query=\"critical issues and blockers\",\n",
    "    filter=Filter(\n",
    "        must=[\n",
    "            # From specific project management tools\n",
    "            FieldCondition(\n",
    "                key=\"source_name\",\n",
    "                match=MatchAny(any=[\"Asana\", \"Jira\", \"Linear\", \"GitHub\"])\n",
    "            ),\n",
    "            # Created in the last 90 days\n",
    "            FieldCondition(\n",
    "                key=\"created_at\",\n",
    "                range=DatetimeRange(\n",
    "                    gte=datetime.now(timezone.utc) - timedelta(days=90)\n",
    "                )\n",
    "            )\n",
    "        ],\n",
    "        should=[\n",
    "            # High priority indicators (at least one must match)\n",
    "            FieldCondition(\n",
    "                key=\"metadata.priority\",\n",
    "                match=MatchAny(any=[\"high\", \"critical\", \"urgent\", \"P0\", \"P1\"])\n",
    "            ),\n",
    "            FieldCondition(\n",
    "                key=\"metadata.labels\",\n",
    "                match=MatchAny(any=[\"blocker\", \"showstopper\", \"critical-bug\"])\n",
    "            )\n",
    "        ],\n",
    "        must_not=[\n",
    "            # Exclude completed items\n",
    "            FieldCondition(\n",
    "                key=\"metadata.status\",\n",
    "                match=MatchAny(any=[\"resolved\", \"closed\", \"done\", \"completed\"])\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    score_threshold=0.6,  # Only show relevant results\n",
    "    limit=20\n",
    ")\n",
    "\n",
    "complex_response = await client.collections.search_collection_advanced(\n",
    "    readable_id=COLLECTION_ID,\n",
    "    search_request=complex_request\n",
    ")\n",
    "\n",
    "display_results(complex_response.results, \"High-Priority Unresolved Items\")\n",
    "\n",
    "# Analyze results by source\n",
    "if complex_response.results:\n",
    "    sources = [r['payload'].get('source_name', 'Unknown') for r in complex_response.results]\n",
    "    source_counts = pd.Series(sources).value_counts()\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    source_counts.plot(kind='bar')\n",
    "    plt.title('High-Priority Items by Source')\n",
    "    plt.xlabel('Source')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Advanced Features\n",
    "\n",
    "Let's explore pagination, score thresholds, and query expansion strategies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 6: Pagination\n",
    "display(Markdown(\"### Pagination Example\"))\n",
    "\n",
    "# Function to fetch all pages\n",
    "async def fetch_all_pages(query: str, filter: Filter = None, page_size: int = 10):\n",
    "    all_results = []\n",
    "    offset = 0\n",
    "    page = 1\n",
    "    \n",
    "    while True:\n",
    "        request = SearchRequest(\n",
    "            query=query,\n",
    "            filter=filter,\n",
    "            limit=page_size,\n",
    "            offset=offset\n",
    "        )\n",
    "        \n",
    "        response = await client.collections.search_collection_advanced(\n",
    "            readable_id=COLLECTION_ID,\n",
    "            search_request=request\n",
    "        )\n",
    "        \n",
    "        if not response.results:\n",
    "            break\n",
    "            \n",
    "        all_results.extend(response.results)\n",
    "        print(f\"Page {page}: Retrieved {len(response.results)} results\")\n",
    "        \n",
    "        # Stop after 3 pages for demo\n",
    "        if page >= 3:\n",
    "            break\n",
    "            \n",
    "        offset += page_size\n",
    "        page += 1\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# Fetch paginated results\n",
    "all_results = await fetch_all_pages(\n",
    "    \"documentation and guides\",\n",
    "    filter=Filter(\n",
    "        must=[\n",
    "            FieldCondition(\n",
    "                key=\"source_name\",\n",
    "                match=MatchAny(any=[\"Confluence\", \"Notion\", \"GitHub\"])\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    page_size=5\n",
    ")\n",
    "\n",
    "display(Markdown(f\"### Total results fetched: {len(all_results)}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 7: Score threshold demonstration\n",
    "display(Markdown(\"### Score Threshold Impact\"))\n",
    "\n",
    "# Compare different score thresholds\n",
    "thresholds = [None, 0.5, 0.7, 0.9]\n",
    "threshold_results = {}\n",
    "\n",
    "for threshold in thresholds:\n",
    "    request = SearchRequest(\n",
    "        query=\"best practices and guidelines\",\n",
    "        score_threshold=threshold,\n",
    "        limit=20\n",
    "    )\n",
    "    \n",
    "    response = await client.collections.search_collection_advanced(\n",
    "        readable_id=COLLECTION_ID,\n",
    "        search_request=request\n",
    "    )\n",
    "    \n",
    "    threshold_results[threshold or \"None\"] = {\n",
    "        'count': len(response.results),\n",
    "        'scores': [r['score'] for r in response.results] if response.results else []\n",
    "    }\n",
    "\n",
    "# Display comparison\n",
    "display(Markdown(\"### Results by Score Threshold\"))\n",
    "for threshold, data in threshold_results.items():\n",
    "    avg_score = sum(data['scores']) / len(data['scores']) if data['scores'] else 0\n",
    "    print(f\"Threshold {threshold}: {data['count']} results, avg score: {avg_score:.3f}\")\n",
    "\n",
    "# Visualize score distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, (threshold, data) in enumerate(threshold_results.items()):\n",
    "    if data['scores']:\n",
    "        axes[i].hist(data['scores'], bins=20, alpha=0.7)\n",
    "        axes[i].set_title(f'Score Distribution (threshold={threshold})')\n",
    "        axes[i].set_xlabel('Score')\n",
    "        axes[i].set_ylabel('Count')\n",
    "        axes[i].axvline(x=float(threshold) if threshold != \"None\" else 0, \n",
    "                       color='red', linestyle='--', label='Threshold')\n",
    "        if threshold != \"None\":\n",
    "            axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 8: Query expansion comparison\n",
    "display(Markdown(\"### Query Expansion Strategies\"))\n",
    "\n",
    "expansion_strategies = [\"no_expansion\", \"auto\", \"llm\"]\n",
    "expansion_results = {}\n",
    "\n",
    "query = \"authentication methods\"\n",
    "\n",
    "for strategy in expansion_strategies:\n",
    "    request = SearchRequest(\n",
    "        query=query,\n",
    "        expansion_strategy=strategy,\n",
    "        limit=10\n",
    "    )\n",
    "    \n",
    "    response = await client.collections.search_collection_advanced(\n",
    "        readable_id=COLLECTION_ID,\n",
    "        search_request=request\n",
    "    )\n",
    "    \n",
    "    expansion_results[strategy] = {\n",
    "        'count': len(response.results),\n",
    "        'sources': list(set([r['payload'].get('source_name', 'Unknown') \n",
    "                           for r in response.results])),\n",
    "        'avg_score': sum(r['score'] for r in response.results) / len(response.results) \n",
    "                    if response.results else 0\n",
    "    }\n",
    "\n",
    "# Display comparison\n",
    "display(Markdown(\"### Expansion Strategy Comparison\"))\n",
    "comparison_df = pd.DataFrame(expansion_results).T\n",
    "comparison_df['sources'] = comparison_df['sources'].apply(lambda x: ', '.join(x))\n",
    "display(comparison_df)\n",
    "\n",
    "# Visualize results count\n",
    "plt.figure(figsize=(8, 5))\n",
    "strategies = list(expansion_results.keys())\n",
    "counts = [expansion_results[s]['count'] for s in strategies]\n",
    "plt.bar(strategies, counts)\n",
    "plt.title(f'Results Count by Expansion Strategy\\nQuery: \"{query}\"')\n",
    "plt.xlabel('Strategy')\n",
    "plt.ylabel('Number of Results')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Real-World Scenarios\n",
    "\n",
    "Let's put it all together with practical examples you might use in production.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 1: Find all critical support tickets from last week\n",
    "display(Markdown(\"### Scenario 1: Critical Support Tickets Dashboard\"))\n",
    "\n",
    "one_week_ago = datetime.now(timezone.utc) - timedelta(days=7)\n",
    "\n",
    "support_request = SearchRequest(\n",
    "    query=\"customer issues problems errors\",\n",
    "    filter=Filter(\n",
    "        must=[\n",
    "            FieldCondition(\n",
    "                key=\"source_name\",\n",
    "                match=MatchAny(any=[\"Zendesk\", \"Intercom\", \"Freshdesk\", \"HelpScout\"])\n",
    "            ),\n",
    "            FieldCondition(\n",
    "                key=\"created_at\",\n",
    "                range=DatetimeRange(gte=one_week_ago)\n",
    "            )\n",
    "        ],\n",
    "        should=[\n",
    "            FieldCondition(\n",
    "                key=\"metadata.priority\",\n",
    "                match=MatchAny(any=[\"urgent\", \"high\", \"critical\"])\n",
    "            ),\n",
    "            FieldCondition(\n",
    "                key=\"metadata.tags\",\n",
    "                match=MatchAny(any=[\"vip\", \"enterprise\", \"paid\"])\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    response_type=\"completion\",\n",
    "    limit=25\n",
    ")\n",
    "\n",
    "support_response = await client.collections.search_collection_advanced(\n",
    "    readable_id=COLLECTION_ID,\n",
    "    search_request=support_request\n",
    ")\n",
    "\n",
    "display(Markdown(\"### AI Summary of Critical Support Issues\"))\n",
    "display(Markdown(support_response.completion))\n",
    "\n",
    "# Show top issues\n",
    "if support_response.results:\n",
    "    display(Markdown(\"\\n### Top Critical Issues\"))\n",
    "    display_results(support_response.results[:5], \"Most Relevant Issues\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 2: Search payment issues across Stripe and Square\n",
    "display(Markdown(\"### Scenario 2: Payment Processing Issues\"))\n",
    "\n",
    "payment_request = SearchRequest(\n",
    "    query=\"payment failed declined error refund chargeback\",\n",
    "    filter=Filter(\n",
    "        must=[\n",
    "            FieldCondition(\n",
    "                key=\"source_name\",\n",
    "                match=MatchAny(any=[\"Stripe\", \"Square\", \"PayPal\", \"Braintree\"])\n",
    "            )\n",
    "        ],\n",
    "        should=[\n",
    "            FieldCondition(\n",
    "                key=\"metadata.type\",\n",
    "                match=MatchAny(any=[\"error\", \"failure\", \"dispute\"])\n",
    "            ),\n",
    "            FieldCondition(\n",
    "                key=\"metadata.amount\",\n",
    "                range=Range(gte=100)  # Focus on larger transactions\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    score_threshold=0.65,\n",
    "    limit=15\n",
    ")\n",
    "\n",
    "payment_response = await client.collections.search_collection_advanced(\n",
    "    readable_id=COLLECTION_ID,\n",
    "    search_request=payment_request\n",
    ")\n",
    "\n",
    "display_results(payment_response.results, \"Payment Issues\")\n",
    "\n",
    "# Analyze by payment provider\n",
    "if payment_response.results:\n",
    "    providers = [r['payload'].get('source_name', 'Unknown') for r in payment_response.results]\n",
    "    provider_counts = pd.Series(providers).value_counts()\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    provider_counts.plot(kind='pie', autopct='%1.1f%%')\n",
    "    plt.title('Payment Issues by Provider')\n",
    "    plt.ylabel('')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario 3: Get engineering docs updated this month\n",
    "display(Markdown(\"### Scenario 3: Recent Engineering Documentation\"))\n",
    "\n",
    "this_month_start = datetime.now(timezone.utc).replace(day=1, hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "docs_request = SearchRequest(\n",
    "    query=\"API documentation guide tutorial implementation\",\n",
    "    filter=Filter(\n",
    "        must=[\n",
    "            FieldCondition(\n",
    "                key=\"source_name\",\n",
    "                match=MatchAny(any=[\"Confluence\", \"Notion\", \"GitHub\"])\n",
    "            ),\n",
    "            FieldCondition(\n",
    "                key=\"created_at\",\n",
    "                range=DatetimeRange(gte=this_month_start)\n",
    "            )\n",
    "        ],\n",
    "        should=[\n",
    "            FieldCondition(\n",
    "                key=\"metadata.type\",\n",
    "                match=MatchAny(any=[\"documentation\", \"guide\", \"readme\", \"wiki\"])\n",
    "            ),\n",
    "            FieldCondition(\n",
    "                key=\"metadata.path\",\n",
    "                match=MatchAny(any=[\"docs/\", \"documentation/\", \"wiki/\"])\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    expansion_strategy=\"llm\",  # Better for technical documentation\n",
    "    limit=20\n",
    ")\n",
    "\n",
    "docs_response = await client.collections.search_collection_advanced(\n",
    "    readable_id=COLLECTION_ID,\n",
    "    search_request=docs_request\n",
    ")\n",
    "\n",
    "display_results(docs_response.results, \"Recent Documentation Updates\")\n",
    "\n",
    "# Group by date\n",
    "if docs_response.results:\n",
    "    dates = []\n",
    "    for r in docs_response.results:\n",
    "        created = r['payload'].get('created_at', '')\n",
    "        if created:\n",
    "            dates.append(pd.to_datetime(created[:10]))\n",
    "    \n",
    "    if dates:\n",
    "        date_counts = pd.Series(dates).dt.date.value_counts().sort_index()\n",
    "        \n",
    "        plt.figure(figsize=(12, 5))\n",
    "        date_counts.plot(kind='bar')\n",
    "        plt.title('Documentation Updates by Date')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Count')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Performance & Best Practices\n",
    "\n",
    "Let's explore how to optimize your searches and avoid common pitfalls.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison: filters vs no filters\n",
    "import time\n",
    "\n",
    "display(Markdown(\"### Performance Impact of Filters\"))\n",
    "\n",
    "# Test 1: Broad search without filters\n",
    "start_time = time.time()\n",
    "broad_response = await client.collections.search_collection(\n",
    "    readable_id=COLLECTION_ID,\n",
    "    query=\"error bug issue problem\",\n",
    "    limit=50\n",
    ")\n",
    "broad_time = time.time() - start_time\n",
    "\n",
    "# Test 2: Filtered search\n",
    "start_time = time.time()\n",
    "filtered_request = SearchRequest(\n",
    "    query=\"error bug issue problem\",\n",
    "    filter=Filter(\n",
    "        must=[\n",
    "            FieldCondition(\n",
    "                key=\"source_name\",\n",
    "                match=MatchValue(value=\"GitHub\")\n",
    "            ),\n",
    "            FieldCondition(\n",
    "                key=\"created_at\",\n",
    "                range=DatetimeRange(\n",
    "                    gte=datetime.now(timezone.utc) - timedelta(days=30)\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    limit=50\n",
    ")\n",
    "filtered_response = await client.collections.search_collection_advanced(\n",
    "    readable_id=COLLECTION_ID,\n",
    "    search_request=filtered_request\n",
    ")\n",
    "filtered_time = time.time() - start_time\n",
    "\n",
    "# Test 3: With score threshold\n",
    "start_time = time.time()\n",
    "threshold_request = SearchRequest(\n",
    "    query=\"error bug issue problem\",\n",
    "    score_threshold=0.7,\n",
    "    limit=50\n",
    ")\n",
    "threshold_response = await client.collections.search_collection_advanced(\n",
    "    readable_id=COLLECTION_ID,\n",
    "    search_request=threshold_request\n",
    ")\n",
    "threshold_time = time.time() - start_time\n",
    "\n",
    "# Display results\n",
    "performance_data = {\n",
    "    'Search Type': ['No Filters', 'With Filters', 'Score Threshold'],\n",
    "    'Time (seconds)': [broad_time, filtered_time, threshold_time],\n",
    "    'Results Count': [len(broad_response.results), \n",
    "                     len(filtered_response.results), \n",
    "                     len(threshold_response.results)]\n",
    "}\n",
    "\n",
    "perf_df = pd.DataFrame(performance_data)\n",
    "display(perf_df)\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "ax1.bar(perf_df['Search Type'], perf_df['Time (seconds)'])\n",
    "ax1.set_title('Search Time Comparison')\n",
    "ax1.set_ylabel('Time (seconds)')\n",
    "ax1.set_xlabel('Search Type')\n",
    "\n",
    "ax2.bar(perf_df['Search Type'], perf_df['Results Count'])\n",
    "ax2.set_title('Results Count Comparison')\n",
    "ax2.set_ylabel('Number of Results')\n",
    "ax2.set_xlabel('Search Type')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Mistakes to Avoid\n",
    "\n",
    "1. **Case Sensitivity**: Always remember that `source_name` is case-sensitive\n",
    "2. **Date Timezones**: Always use timezone-aware datetime objects\n",
    "3. **Over-filtering**: Start broad and narrow down gradually\n",
    "4. **Score Thresholds**: Don't set too high initially - you might miss relevant results\n",
    "5. **Pagination Limits**: Maximum limit is 100 results per page\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "- **Filters are powerful**: Combine semantic search with metadata filtering for precise results\n",
    "- **Case matters**: Use `MatchAny` for case-insensitive matching\n",
    "- **Start simple**: Begin with basic filters and add complexity as needed\n",
    "- **Monitor performance**: Filters can significantly improve search speed\n",
    "- **Use the right response type**: `raw` for data processing, `completion` for summaries\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Explore the [API documentation](https://docs.airweave.ai/api-reference) for more details\n",
    "2. Try these examples with your own data\n",
    "3. Experiment with different filter combinations\n",
    "4. Join our [community](https://discord.gg/airweave) for support and best practices\n",
    "\n",
    "Happy searching! üîç‚ú®\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
