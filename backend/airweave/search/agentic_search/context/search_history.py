"""Search history context building for agentic search.

This module provides utilities for building search history context for LLM prompts.
Both the Planner and Judge use this to understand what happened in previous iterations.
"""

from __future__ import annotations

from dataclasses import dataclass
from typing import TYPE_CHECKING, List, Optional

if TYPE_CHECKING:
    from airweave.search.agentic_search.builder.schemas import VespaQuery
    from airweave.search.agentic_search.judge.schemas import Judgement
    from airweave.search.agentic_search.planner.schemas import SearchPlan
    from airweave.search.agentic_search.state import AgenticSearchState


@dataclass
class IterationSummary:
    """Summary of a single iteration for history context.

    Uses the full schema objects instead of extracting individual fields.
    This keeps the data model clean and avoids duplication.

    Attributes:
        iteration: The iteration number (0-indexed)
        plan: The SearchPlan generated by the planner
        vespa_query: The VespaQuery built from the plan (includes YQL, limit, offset, params)
        result_count: Number of results returned
        error: Error message if the query failed
        judgement: The Judgement from the judge (if iteration was judged)
    """

    iteration: int
    plan: "SearchPlan"
    vespa_query: Optional["VespaQuery"]
    result_count: int
    error: Optional[str]
    judgement: Optional["Judgement"]


class SearchHistoryBuilder:
    """Builds search history context for LLM prompts.

    Used by both Planner and Judge to include relevant history in their prompts.
    Handles budget management by omitting older iterations (not truncating content).

    Usage:
        builder = SearchHistoryBuilder(state)
        summaries = builder.get_iteration_summaries()
        markdown = builder.format_history_markdown(max_iterations=3)
    """

    def __init__(self, state: "AgenticSearchState") -> None:
        """Initialize the search history builder.

        Args:
            state: The agentic search state containing all iteration data
        """
        self.state = state

    def get_iteration_summaries(
        self,
        max_iterations: Optional[int] = None,
        most_recent_first: bool = True,
    ) -> List[IterationSummary]:
        """Get summaries of past iterations.

        Args:
            max_iterations: Maximum number of iterations to include (None = all)
            most_recent_first: If True, return most recent first (for budget fitting)

        Returns:
            List of IterationSummary objects
        """
        if self.state.iteration == 0:
            return []

        summaries = []
        for i in range(self.state.iteration):
            plan = self.state.plans.get(i)
            if plan is None:
                continue  # Skip iterations without a plan

            summary = IterationSummary(
                iteration=i,
                plan=plan,
                vespa_query=self.state.vespa_queries.get(i),
                result_count=len(self.state.results.get(i, [])),
                error=self.state.errors.get(i),
                judgement=self.state.judgements.get(i),
            )
            summaries.append(summary)

        if most_recent_first:
            summaries.reverse()

        if max_iterations is not None:
            summaries = summaries[:max_iterations]

        return summaries

    def format_iteration_markdown(  # noqa: C901 - formatting function, complexity acceptable
        self,
        summary: IterationSummary,
        include_vespa_query: bool = True,
        include_judgement: bool = True,
    ) -> str:
        """Format a single iteration as markdown.

        Args:
            summary: The iteration summary
            include_vespa_query: Whether to include VespaQuery details
            include_judgement: Whether to include judgement details

        Returns:
            Markdown for this iteration
        """
        lines = [
            f"### Iteration {summary.iteration + 1}",
            "",
        ]

        # Plan
        lines.append("**Plan:**")
        lines.append(f"- Queries: {summary.plan.queries}")
        lines.append(f"- Strategy: {summary.plan.retrieval_strategy.value}")
        lines.append(f"- Limit: {summary.plan.limit}, Offset: {summary.plan.offset}")
        if summary.plan.filter_groups:
            lines.append(f"- Filter groups: {len(summary.plan.filter_groups)}")
            for i, group in enumerate(summary.plan.filter_groups, 1):
                conditions_str = ", ".join(
                    f"{c.field} {c.operator.value} {c.value!r}" for c in group.conditions
                )
                lines.append(f"  - Group {i}: {conditions_str}")
        lines.append(f"- Reasoning: {summary.plan.reasoning}")
        lines.append("")

        # VespaQuery (YQL + params)
        if include_vespa_query and summary.vespa_query is not None:
            lines.append("**Vespa Query:**")
            lines.append(f"```yql\n{summary.vespa_query.yql}\n```")
            lines.append("")
            # Include params (excluding embedding vectors which are too large)
            if summary.vespa_query.params:
                lines.append("**Query Params:**")
                lines.append(f"```\n{summary.vespa_query.format_params_for_logging()}\n```")
                lines.append("")

        # Results count
        lines.append(f"**Results:** {summary.result_count} returned")
        lines.append("")

        # Error (if any)
        if summary.error:
            lines.append("**Error:**")
            lines.append(f"```\n{summary.error}\n```")
            lines.append("")

        # Judgement
        if include_judgement and summary.judgement is not None:
            lines.append("**Judge Evaluation:**")
            # Format judgement fields (duck-typed to work with any Judgement-like object)
            if hasattr(summary.judgement, "should_continue"):
                lines.append(f"- Should continue: {summary.judgement.should_continue}")
            if hasattr(summary.judgement, "reasoning"):
                lines.append(f"- Reasoning: {summary.judgement.reasoning}")
            if hasattr(summary.judgement, "advice") and summary.judgement.advice:
                lines.append(f"- Advice: {summary.judgement.advice}")
            if hasattr(summary.judgement, "error_analysis") and summary.judgement.error_analysis:
                lines.append(f"- Error analysis: {summary.judgement.error_analysis}")
            if (
                hasattr(summary.judgement, "useful_result_ids")
                and summary.judgement.useful_result_ids
            ):
                lines.append(f"- Useful result IDs: {summary.judgement.useful_result_ids}")
            lines.append("")

            # Include result summaries from the judgement
            if (
                hasattr(summary.judgement, "result_summaries")
                and summary.judgement.result_summaries
            ):
                lines.append("**Result Summaries:**")
                for rs in summary.judgement.result_summaries:
                    lines.append(f"- **{rs.name}** (`{rs.entity_id}`)")
                    if hasattr(rs, "content_summary"):
                        lines.append(f"  - Content: {rs.content_summary}")
                    lines.append(f"  - Relevance: {rs.relevance}")
                    lines.append(f"  - Useful: {rs.useful}")
                lines.append("")

        lines.append("---")
        lines.append("")

        return "\n".join(lines)

    def format_history_markdown(
        self,
        max_iterations: Optional[int] = None,
        include_vespa_queries: bool = True,
        include_judgements: bool = True,
    ) -> str:
        """Format search history as markdown for LLM context.

        Args:
            max_iterations: Maximum iterations to include (None = all, prioritizes recent)
            include_vespa_queries: Whether to include VespaQuery details
            include_judgements: Whether to include judgement details

        Returns:
            Markdown-formatted search history
        """
        if self.state.is_first_iteration:
            return "(No previous iterations)"

        summaries = self.get_iteration_summaries(
            max_iterations=max_iterations,
            most_recent_first=False,  # Chronological order for display
        )

        if not summaries:
            return "(No previous iterations)"

        lines = []

        # Note if we're omitting old iterations
        total_iterations = self.state.iteration
        included_iterations = len(summaries)
        if max_iterations is not None and included_iterations < total_iterations:
            omitted = total_iterations - included_iterations
            lines.append(f"*Note: {omitted} oldest iteration(s) omitted to fit context window*")
            lines.append("")

        for summary in summaries:
            lines.append(
                self.format_iteration_markdown(
                    summary,
                    include_vespa_query=include_vespa_queries,
                    include_judgement=include_judgements,
                )
            )

        return "\n".join(lines)

    def format_history_with_budget(
        self,
        max_tokens: int,
        token_counter: callable,
        include_vespa_queries: bool = True,
        include_judgements: bool = True,
    ) -> str:
        """Format history to fit within token budget.

        Starts with most recent iteration, adds more until budget exhausted.
        Omits oldest iterations entirely (no truncation).

        Args:
            max_tokens: Maximum tokens allowed for history
            token_counter: Function to count tokens in a string
            include_vespa_queries: Whether to include VespaQuery details
            include_judgements: Whether to include judgement details

        Returns:
            Markdown history that fits within budget
        """
        if self.state.is_first_iteration:
            return "(No previous iterations)"

        # Get summaries most-recent-first for budget fitting
        summaries = self.get_iteration_summaries(most_recent_first=True)

        if not summaries:
            return "(No previous iterations)"

        # Build up history starting from most recent
        included_summaries: List[IterationSummary] = []
        current_tokens = 0

        for summary in summaries:
            iteration_md = self.format_iteration_markdown(
                summary,
                include_vespa_query=include_vespa_queries,
                include_judgement=include_judgements,
            )
            iteration_tokens = token_counter(iteration_md)

            if current_tokens + iteration_tokens > max_tokens:
                break  # Can't fit this iteration

            included_summaries.append(summary)
            current_tokens += iteration_tokens

        if not included_summaries:
            return "(Previous iterations omitted to fit context window)"

        # Reverse back to chronological order for display
        included_summaries.reverse()

        lines = []

        # Note if we're omitting old iterations
        total_iterations = self.state.iteration
        included_iterations = len(included_summaries)
        if included_iterations < total_iterations:
            omitted = total_iterations - included_iterations
            lines.append(f"*Note: {omitted} oldest iteration(s) omitted to fit context window*")
            lines.append("")

        for summary in included_summaries:
            lines.append(
                self.format_iteration_markdown(
                    summary,
                    include_vespa_query=include_vespa_queries,
                    include_judgement=include_judgements,
                )
            )

        return "\n".join(lines)
